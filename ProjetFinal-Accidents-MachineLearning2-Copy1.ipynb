{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project - Road Accidents in France in 2019\n",
    "## N°2 / Module 'Imbalanced-Learn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, BalancedBaggingClassifier, RUSBoostClassifier, EasyEnsembleClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des fichiers de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.read_csv('../Final-Project/data/victime_clean_dummies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130901, 141)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = acc.pop('grav')\n",
    "X = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choix et Entraînement de divers modèles initialisés par défaut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour évaluer nos modèles, nous utiliserons le score de Balanced Accuracy (\"exactitude pondérée\") plutôt que le score d'Accuracy, car nos classes cibles sont de tailles respectives déséquilibrées. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On essaie plusieurs modèles de classification, initialisés par défaut.\n",
    "https://scikit-learn.org/stable/modules/multiclass.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un second temps, on utilise la solution proposée par le module imblearn.ensemble : des modèles d'ensembles entraînés à chaque étape sur un échantillon rééquilibré automatiquement entre les différentes classes. Ce qui permet de se passer de méthodes de rééchantillonnage avant l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BalancedRandomForestClassifier()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modèle : BALANCED FOREST\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "brf1 = BalancedRandomForestClassifier()\n",
    "brf1.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#brf1_scores = cross_val_score(brf1, X_train, y_train, scoring='balanced_accuracy', cv=10)\n",
    "#display_scores(brf1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Balanced Accuracy Score on Train Set = 0.736\n"
     ]
    }
   ],
   "source": [
    "brf1_pred_train = brf1.predict(X_train)\n",
    "brf1_train_score = balanced_accuracy_score(y_train, brf1_pred_train)\n",
    "print(\"Final Balanced Accuracy Score on Train Set =\", round(brf1_train_score,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Balanced Accuracy Score on Test Set = 0.561\n"
     ]
    }
   ],
   "source": [
    "brf1_pred_test = brf1.predict(X_test)\n",
    "brf1_test_score = balanced_accuracy_score(y_test, brf1_pred_test)\n",
    "print(\"Final Balanced Accuracy Score on Test Set =\", round(brf1_test_score,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BalancedBaggingClassifier()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modèle : BALANCED BAGGING\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "bbc1 = BalancedBaggingClassifier()\n",
    "bbc1.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Balanced Accuracy Score on Train Set = 0.722\n"
     ]
    }
   ],
   "source": [
    "bbc1_pred_train = bbc1.predict(X_train)\n",
    "bbc1_train_score = balanced_accuracy_score(y_train, bbc1_pred_train)\n",
    "print(\"Final Balanced Accuracy Score on Train Set =\", round(bbc1_train_score,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Balanced Accuracy Score on Test Set = 0.539\n"
     ]
    }
   ],
   "source": [
    "bbc1_pred_test = bbc1.predict(X_test)\n",
    "bbc1_test_score = balanced_accuracy_score(y_test, bbc1_pred_test)\n",
    "print(\"Final Balanced Accuracy Score on Test Set =\", round(bbc1_test_score,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RUSBoostClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modèle : RUS BOOST\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "rusboost1 = RUSBoostClassifier()\n",
    "rusboost1.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Balanced Accuracy Score on Train Set = 0.494\n"
     ]
    }
   ],
   "source": [
    "rusboost1_pred_train = rusboost1.predict(X_train)\n",
    "rusboost1_train_score = balanced_accuracy_score(y_train, rusboost1_pred_train)\n",
    "print(\"Final Balanced Accuracy Score on Train Set =\", round(rusboost1_train_score,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Balanced Accuracy Score on Test Set = 0.496\n"
     ]
    }
   ],
   "source": [
    "rusboost1_pred_test = rusboost1.predict(X_test)\n",
    "rusboost1_test_score = balanced_accuracy_score(y_test, rusboost1_pred_test)\n",
    "print(\"Final Balanced Accuracy Score on Test Set =\", round(rusboost1_test_score,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EasyEnsembleClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modèle : EASY ENSEMBLE\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "ee1 = EasyEnsembleClassifier()\n",
    "ee1.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Balanced Accuracy Score on Train Set = 0.532\n"
     ]
    }
   ],
   "source": [
    "ee1_pred_train = ee1.predict(X_train)\n",
    "ee1_train_score = balanced_accuracy_score(y_train, ee1_pred_train)\n",
    "print(\"Final Balanced Accuracy Score on Train Set =\", round(ee1_train_score,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Balanced Accuracy Score on Test Set = 0.529\n"
     ]
    }
   ],
   "source": [
    "ee1_pred_test = ee1.predict(X_test)\n",
    "ee1_test_score = balanced_accuracy_score(y_test, ee1_pred_test)\n",
    "print(\"Final Balanced Accuracy Score on Test Set =\", round(ee1_test_score,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations :**\n",
    "Avec un score très de 56% sur le test, le modèle \"Balanced Forest Classifier\" est le plus prometteur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    }
   ],
   "source": [
    "print(\"finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Validation des modèles\n",
    "\n",
    "Le jeu d'apprentissage est scindé en 10 \"sous-jeux\", et l'apprentissage a lieu 10 fois d'affilée sur 9 sous-jeux différents avec une évaluation sur le 10ème sous-jeu (\"pli de validation\"). \n",
    "On obtient donc 10 scores distincts d'apprentissage, dont on calcule la moyenne et l'écart-type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation using balanced accuracy score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Balanced Accuracy Scores:\", scores)\n",
    "    print(\"Mean Balanced Accuracy Score:\", round(scores.mean(),3))\n",
    "    print(\"Standard deviation:\", round(scores.std(),5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réglage des Hyperparamètres avec RandomSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons d'améliorer le modèle Gradient Boosting en jouant sur ses hyper-paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc2 = GradientBoostingClassifier()\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "parameters = {\"learning_rate\": [0.001, 0.01, 0.1, 0.2],\n",
    "              \"n_estimators\" : [100, 500, 1000, 1500],\n",
    "              \"subsample\"    : [0.5, 0.7, 1.0, 1.5],\n",
    "              \"max_features\" : ['sqrt','log2',2,50,140],\n",
    "              #'min_samples_split':[2,4,6],\n",
    "              #'min_samples_leaf':[3,5,7],\n",
    "              \"max_depth\"    : [2, 3, 10, 15, 20]\n",
    "              }\n",
    "\n",
    "randm = RandomizedSearchCV(gbc2, parameters, n_jobs=-1, scoring = 'balanced_accuracy')\n",
    "randm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The mean cross-validated score of the best estimator is: {randm.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Finale sur le Jeu de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = randm.best_estimator_\n",
    "\n",
    "final_pred_test = final_model.predict(X_test)\n",
    "\n",
    "final_score_test = balanced_accuracy_score(y_test, final_pred_test)\n",
    "\n",
    "print(\"Final Balanced Accuracy Score on Test Set =\", round(final_score_test,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Conclusion :**\n",
    "Notre modèle le plus performant est décevant avec un score de balanced accuracy inférieur à 50%.\n",
    "Pistes d'amélioration : undersampling des 2 classes majoritaires, rajout de features pour complexifier le jeu d'apprentissage, sélection d'autres algorithmes plus complexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables les plus importantes\n",
    "Etudions les variables qui sont plus déterminantes que les autres dans la classification par notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_importances = randm.best_estimator_.feature_importances_\n",
    "#list_feat = list(feature_importances)\n",
    "#list_col = list(X_train.columns)\n",
    "#sorted([t for t in zip(list_feat, list_col)], key=lambda t: t[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour sauvegarder le modèle\n",
    "#joblib.dump(randm.best_estimator_, \"my_model_2021-08-05.pkl\")\n",
    "# Pour le réutiliser\n",
    "#my_model_loaded = joblib.load(\"my_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
