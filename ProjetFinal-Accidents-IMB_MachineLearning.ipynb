{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project - Road Accidents in France in 2019\n",
    "## N°2 / Module 'Imbalanced-Learn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, BalancedBaggingClassifier, RUSBoostClassifier, EasyEnsembleClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des fichiers de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.read_csv('../Final-Project/data/victime_clean_dummies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130901, 141)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = acc.pop('grav')\n",
    "X = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour l'évaluation des modèles, nous utiliserons le score de Balanced Accuracy (\"exactitude pondérée\") \n",
    "# plutôt que le score d'Accuracy, car nos classes cibles sont de tailles respectives déséquilibrées. \n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Mean Balanced Accuracy Score:\", round(scores.mean(),3))\n",
    "    print(\"Standard deviation:\", round(scores.std(),5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choix et Entraînement de divers modèles initialisés par défaut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On essaie plusieurs modèles de classification, initialisés par défaut.\n",
    "https://scikit-learn.org/stable/modules/multiclass.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un second temps, on utilise la solution proposée par le module imblearn.ensemble : des modèles d'ensembles entraînés à chaque étape sur un échantillon rééquilibré automatiquement entre les différentes classes. Ce qui permet de se passer de méthodes de rééchantillonnage avant l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle : BALANCED FOREST\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "brf1 = BalancedRandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Balanced Accuracy Score: 0.559\n",
      "Standard deviation: 0.00701\n"
     ]
    }
   ],
   "source": [
    "brf1_scores = cross_val_score(brf1, X_train, y_train, scoring='balanced_accuracy', cv=10)\n",
    "display_scores(brf1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val= train_test_split(X_train, y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BalancedRandomForestClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = brf1.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5601577149423805"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_val, y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.77      0.76      4964\n",
      "           2       0.11      0.64      0.19       301\n",
      "           3       0.37      0.36      0.36      1833\n",
      "           4       0.70      0.47      0.56      4683\n",
      "\n",
      "    accuracy                           0.58     11781\n",
      "   macro avg       0.48      0.56      0.47     11781\n",
      "weighted avg       0.65      0.58      0.61     11781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7719581 , 0.06466559, 0.04774376, 0.11563255],\n",
       "       [0.05980066, 0.63787375, 0.24252492, 0.05980066],\n",
       "       [0.09056192, 0.34969995, 0.35951991, 0.20021822],\n",
       "       [0.23361093, 0.11787316, 0.17723681, 0.47127909]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, y_pred_val, normalize=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11781,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  641,  1032,  1271,  2313,  3549,  3945,  4479,  4776,  5345,\n",
       "        6380,  7103,  7295,  7372,  8209,  9613, 10003, 10257, 10673],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.intersect1d(np.where(y_val == 2)[0], np.where(y_pred_val == 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/victime_clean_forTableau.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mois                              11\n",
       "lum                                5\n",
       "dep                    Ile de france\n",
       "agglo                              2\n",
       "intersection                   IRLVT\n",
       "meteo                              2\n",
       "collision                          2\n",
       "type_route                         3\n",
       "type_circu                         2\n",
       "nb_voies                           4\n",
       "declivite                          1\n",
       "rectitude                          1\n",
       "surface                            2\n",
       "infrastructure                 IRLVT\n",
       "situ_acc                           1\n",
       "vitesse_autorisee                 50\n",
       "sens_circu                         2\n",
       "type_veh                           7\n",
       "obst_fixe                      IRLVT\n",
       "obst_mobile                        2\n",
       "choc                               1\n",
       "manoeuvre_veh                      1\n",
       "num_veh                          A01\n",
       "place_veh                          1\n",
       "type_usager                        1\n",
       "sexe                               1\n",
       "an_nais              Moins de 35 ans\n",
       "loc_pieton                     IRLVT\n",
       "pieton_seul                    IRLVT\n",
       "grav                               1\n",
       "Name: 2019, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mois                             6\n",
       "lum                              1\n",
       "dep                  Ile de france\n",
       "agglo                            2\n",
       "intersection                     2\n",
       "meteo                            1\n",
       "collision                        6\n",
       "type_route                       3\n",
       "type_circu                       3\n",
       "nb_voies                         4\n",
       "declivite                        1\n",
       "rectitude                        1\n",
       "surface                          1\n",
       "infrastructure                   5\n",
       "situ_acc                         1\n",
       "vitesse_autorisee               70\n",
       "sens_circu                       1\n",
       "type_veh                         7\n",
       "obst_fixe                    IRLVT\n",
       "obst_mobile                      2\n",
       "choc                             4\n",
       "manoeuvre_veh                    1\n",
       "num_veh                        B01\n",
       "place_veh                        1\n",
       "type_usager                      1\n",
       "sexe                             2\n",
       "an_nais                  36-75 ans\n",
       "loc_pieton                   IRLVT\n",
       "pieton_seul                  IRLVT\n",
       "grav                             4\n",
       "Name: 3324, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[3324]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle : BALANCED BAGGING\n",
    "bbc1 = BalancedBaggingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Balanced Accuracy Score: 0.523\n",
      "Standard deviation: 0.00579\n"
     ]
    }
   ],
   "source": [
    "bbc1_scores = cross_val_score(bbc1, X_train, y_train, scoring='balanced_accuracy', cv=10)\n",
    "display_scores(bbc1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RUSBoostClassifier()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modèle : RUS BOOST\n",
    "rusboost1 = RUSBoostClassifier()\n",
    "rusboost1.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Balanced Accuracy Score: 0.482\n",
      "Standard deviation: 0.00973\n"
     ]
    }
   ],
   "source": [
    "rusboost1_scores = cross_val_score(rusboost1, X_train, y_train, scoring='balanced_accuracy', cv=10)\n",
    "display_scores(rusboost1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle : EASY ENSEMBLE\n",
    "ee1 = EasyEnsembleClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Balanced Accuracy Score: 0.528\n",
      "Standard deviation: 0.0028\n"
     ]
    }
   ],
   "source": [
    "ee1_scores = cross_val_score(ee1, X_train, y_train, scoring='balanced_accuracy', cv=10)\n",
    "display_scores(ee1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESUME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_c0d6adc0_f79f_11eb_91e2_b9cc9fbfc9f6\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Model Name</th>        <th class=\"col_heading level0 col1\" >Balanced Accuracy on Train</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_c0d6adc0_f79f_11eb_91e2_b9cc9fbfc9f6row0_col0\" class=\"data row0 col0\" >BalancedRandomForestClassifier</td>\n",
       "                        <td id=\"T_c0d6adc0_f79f_11eb_91e2_b9cc9fbfc9f6row0_col1\" class=\"data row0 col1\" >0.559266</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_c0d6adc0_f79f_11eb_91e2_b9cc9fbfc9f6row1_col0\" class=\"data row1 col0\" >EasyEnsembleClassifier</td>\n",
       "                        <td id=\"T_c0d6adc0_f79f_11eb_91e2_b9cc9fbfc9f6row1_col1\" class=\"data row1 col1\" >0.527648</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_c0d6adc0_f79f_11eb_91e2_b9cc9fbfc9f6row2_col0\" class=\"data row2 col0\" >BalancedBaggingClassifier</td>\n",
       "                        <td id=\"T_c0d6adc0_f79f_11eb_91e2_b9cc9fbfc9f6row2_col1\" class=\"data row2 col1\" >0.522711</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_c0d6adc0_f79f_11eb_91e2_b9cc9fbfc9f6row3_col0\" class=\"data row3 col0\" >RUSBoostClassifier</td>\n",
       "                        <td id=\"T_c0d6adc0_f79f_11eb_91e2_b9cc9fbfc9f6row3_col1\" class=\"data row3 col1\" >0.482152</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b4c4d272b0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scordict = { \"Model Name\":[\"BalancedRandomForestClassifier\", 'BalancedBaggingClassifier', 'RUSBoostClassifier', 'EasyEnsembleClassifier'],\n",
    "            \"Balanced Accuracy on Train\": [brf1_scores.mean(), bbc1_scores.mean(), rusboost1_scores.mean(), ee1_scores.mean()]\n",
    "           }\n",
    "df_scores = pd.DataFrame(scordict)\n",
    "df_scores.sort_values(by='Balanced Accuracy on Train',ascending=False).style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONCLUSION\n",
    "Avec un score de 55% sur le jeu d'entraînement, le modèle \"Balanced Forest Classifier\" est le plus prometteur, mais reste insuffisant.\n",
    "\n",
    "Pistes d'amélioration : undersampling des 2 classes majoritaires, rajout de features pour complexifier le jeu d'apprentissage, sélection d'autres algorithmes plus complexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    }
   ],
   "source": [
    "print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réglage des Hyperparamètres avec RandomSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons d'améliorer le modèle Gradient Boosting en jouant sur ses hyper-paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary -: 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-7511cbc02f8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m parameters = {\"learning_rate\": [0.001, 0.01, 0.1, 0.2],\n",
      "\u001b[1;31mTypeError\u001b[0m: bad operand type for unary -: 'tuple'"
     ]
    }
   ],
   "source": [
    "model = -----()\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "parameters = {\"learning_rate\": [0.001, 0.01, 0.1, 0.2],\n",
    "              \"n_estimators\" : [100, 500, 1000, 1500],\n",
    "              \"subsample\"    : [0.5, 0.7, 1.0, 1.5],\n",
    "              \"max_features\" : ['sqrt','log2',2,50,140],\n",
    "              #'min_samples_split':[2,4,6],\n",
    "              #'min_samples_leaf':[3,5,7],\n",
    "              \"max_depth\"    : [2, 3, 10, 15, 20]\n",
    "              }\n",
    "\n",
    "randm = RandomizedSearchCV(model, parameters, n_jobs=-1, scoring = 'balanced_accuracy')\n",
    "randm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The mean cross-validated score of the best estimator is: {randm.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Finale sur le Jeu de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = randm.best_estimator_\n",
    "\n",
    "final_pred_test = final_model.predict(X_test)\n",
    "\n",
    "final_score_test = balanced_accuracy_score(y_test, final_pred_test)\n",
    "\n",
    "print(\"Final Balanced Accuracy Score on Test Set =\", round(final_score_test,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables les plus importantes\n",
    "Etudions les variables qui sont plus déterminantes que les autres dans la classification par notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_importances = randm.best_estimator_.feature_importances_\n",
    "#list_feat = list(feature_importances)\n",
    "#list_col = list(X_train.columns)\n",
    "#sorted([t for t in zip(list_feat, list_col)], key=lambda t: t[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour sauvegarder le modèle\n",
    "#joblib.dump(randm.best_estimator_, \"my_model_2021-08-05.pkl\")\n",
    "# Pour le réutiliser\n",
    "#my_model_loaded = joblib.load(\"my_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
