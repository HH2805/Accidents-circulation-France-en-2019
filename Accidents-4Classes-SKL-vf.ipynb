{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project - Road Accidents in France in 2019\n",
    "## N°1 / \"SciKit-Learn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, classification_report\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost \n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des fichiers de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mailb\\\\Documents_Administrateur\\\\Ironhack\\\\DA_BOOTCAMP\\\\3.Labs\\\\dataV2-labs\\\\module-3\\\\Final-Project'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.read_csv('../Final-Project/data/victime_clean_dummies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130901, 141)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = acc.pop('grav')\n",
    "X = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour l'évaluation des modèles, nous utiliserons le score de Balanced Accuracy (\"exactitude pondérée\") \n",
    "# plutôt que le score d'Accuracy, car nos classes cibles sont de tailles respectives déséquilibrées. \n",
    "\n",
    "def display_scores(scores):\n",
    "    meansc = round(scores.mean(),3)\n",
    "    print(meansc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choix et Entraînement de divers modèles initialisés par défaut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On essaie plusieurs modèles de classification, initialisés par défaut.\n",
    "https://scikit-learn.org/stable/modules/multiclass.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inherently Multiclass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Premier modèle : RANDOM FOREST\n",
    "rf1 = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.473\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation (Le jeu d'apprentissage est scindé en \"sous-jeux\", et l'apprentissage a lieu n fois d'affilée sur n-1 sous-jeux différents avec une évaluation sur le nème sous-jeu (\"pli de validation\").)\n",
    "rf1_bacc = cross_val_score(rf1, X_train, y_train, scoring='balanced_accuracy', cv=5)\n",
    "display_scores(rf1_bacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.665\n"
     ]
    }
   ],
   "source": [
    "rf1_acc = cross_val_score(rf1, X_train, y_train, scoring='accuracy', cv=5)\n",
    "display_scores(rf1_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('type_veh_7', 0.03301963657582155),\n",
       " ('vitesse_autorisee', 0.03063209684341509),\n",
       " ('nb_voies', 0.030480655838332368),\n",
       " ('sens_circu_2', 0.019635091687577374),\n",
       " ('sexe_2', 0.019335973430766724),\n",
       " ('num_veh_B01', 0.018645806655334603),\n",
       " ('obst_fixe_IRLVT', 0.0162515647888668),\n",
       " ('dep_Sud Est', 0.015891639075574712),\n",
       " ('type_usager_2', 0.01570314511767067),\n",
       " ('obst_mobile_IRLVT', 0.015486179297941365),\n",
       " ('obst_mobile_2', 0.014696369622052317),\n",
       " ('type_veh_33', 0.014612567281410398),\n",
       " ('declivite_2', 0.014173262972065299),\n",
       " ('type_veh_10', 0.013975955985319845),\n",
       " ('an_nais_Moins de 35 ans', 0.0139022146161148)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(X.columns[i], rf1.feature_importances_[i]) for i in np.argsort(rf1.feature_importances_)[::-1]][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle : EXTRA-TREES\n",
    "etc1 = ExtraTreesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.476\n"
     ]
    }
   ],
   "source": [
    "# Cross-evaluation \n",
    "etc1_bacc = cross_val_score(etc1, X_train, y_train, scoring='balanced_accuracy', cv=5)\n",
    "display_scores(etc1_bacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.659\n"
     ]
    }
   ],
   "source": [
    "# Cross-evaluation \n",
    "etc1_acc = cross_val_score(etc1, X_train, y_train, scoring='accuracy', cv=5)\n",
    "display_scores(etc1_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etc1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('type_veh_7', 0.030869811880863282),\n",
       " ('vitesse_autorisee', 0.02399364945806883),\n",
       " ('nb_voies', 0.023729800574725516),\n",
       " ('sens_circu_2', 0.0206336392603733),\n",
       " ('sexe_2', 0.019370044840830467),\n",
       " ('num_veh_B01', 0.01813940875340833),\n",
       " ('obst_mobile_IRLVT', 0.016849235359733653),\n",
       " ('obst_fixe_IRLVT', 0.016758927955151267),\n",
       " ('type_veh_33', 0.016695703416682334),\n",
       " ('type_usager_2', 0.016332573015431423),\n",
       " ('dep_Sud Est', 0.015749953186197353),\n",
       " ('declivite_2', 0.014571885614955083),\n",
       " ('agglo_2', 0.014389395905987026),\n",
       " ('obst_mobile_2', 0.013861692429197148),\n",
       " ('type_veh_10', 0.013409542563586474)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(X.columns[i], etc1.feature_importances_[i]) for i in np.argsort(etc1.feature_importances_)[::-1]][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle : GRADIENT BOOSTING\n",
    "gbc11 = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.448\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation \n",
    "gbc11_bacc = cross_val_score(gbc11, X_train, y_train, scoring='balanced_accuracy', cv=5)\n",
    "display_scores(gbc11_bacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.653\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "gbc11_acc = cross_val_score(gbc11, X_train, y_train, scoring='accuracy', cv=5)\n",
    "display_scores(gbc11_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc11.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('type_veh_7', 0.1234594715105385),\n",
       " ('type_veh_10', 0.09966840837786956),\n",
       " ('obst_fixe_IRLVT', 0.07434117432815562),\n",
       " ('place_veh_10', 0.06388817690928968),\n",
       " ('type_veh_autre', 0.04921001919162119),\n",
       " ('obst_mobile_IRLVT', 0.0459610008675671),\n",
       " ('obst_mobile_2', 0.04571566008098366),\n",
       " ('agglo_2', 0.04536871352161132),\n",
       " ('pieton_seul_IRLVT', 0.040245049080619204),\n",
       " ('type_usager_3', 0.03985143423099702),\n",
       " ('num_veh_B01', 0.03004666143306421),\n",
       " ('type_usager_2', 0.025781138781970633),\n",
       " ('loc_pieton_IRLVT', 0.02531769038563318),\n",
       " ('sexe_2', 0.024746988544572295),\n",
       " ('type_veh_33', 0.020852317640815722)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(X.columns[i], gbc11.feature_importances_[i]) for i in np.argsort(gbc11.feature_importances_)[::-1]][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle : XGBoost\n",
    "xgb1 = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mailb\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:21:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mailb\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:22:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mailb\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:23:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mailb\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:24:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mailb\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:25:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.486\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "xgb1_bacc = cross_val_score(xgb1, X_train, y_train, scoring='balanced_accuracy', cv=5)\n",
    "display_scores(xgb1_bacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mailb\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:26:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mailb\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:27:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mailb\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:28:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mailb\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mailb\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:30:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.67\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "xgb1_acc = cross_val_score(xgb1, X_train, y_train, scoring='accuracy', cv=5)\n",
    "display_scores(xgb1_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle : LigthGBM\n",
    "lgbm1 = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.479\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "lgbm1_bacc = cross_val_score(lgbm1, X_train, y_train, scoring='balanced_accuracy', cv=5)\n",
    "display_scores(lgbm1_bacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.668\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "lgbm1_acc = cross_val_score(lgbm1, X_train, y_train, scoring='accuracy', cv=5)\n",
    "display_scores(lgbm1_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle : CatBoost\n",
    "cat1 = CatBoostClassifier(verbose=0, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.485\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "cat1_bacc = cross_val_score(cat1, X_train, y_train, scoring='balanced_accuracy', cv=5, error_score='raise', verbose=0)\n",
    "display_scores(cat1_bacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.673\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "cat1_acc = cross_val_score(cat1, X_train, y_train, scoring='accuracy', cv=5, error_score='raise', verbose=0)\n",
    "display_scores(cat1_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle : LOGISTIC REGRESSION (MULTI-CLASS)\n",
    "logreg1 = LogisticRegression(multi_class= \"multinomial\", max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.456\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "logreg1_bacc = cross_val_score(logreg1, X_train, y_train, scoring='balanced_accuracy', cv=5)\n",
    "display_scores(logreg1_bacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.652\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "logreg1_acc = cross_val_score(logreg1, X_train, y_train, scoring='accuracy', cv=5)\n",
    "display_scores(logreg1_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiclass as One-Vs-The-Rest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle : Multiclass as One-Vs-The-Rest / PERCEPTRON\n",
    "pclf = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.349\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "pclf_bacc = cross_val_score(pclf, X_train, y_train, scoring='balanced_accuracy', cv=5)\n",
    "display_scores(pclf_bacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "pclf_acc = cross_val_score(pclf, X_train, y_train, scoring='accuracy', cv=5)\n",
    "display_scores(pclf_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un second fichier, on utilisera la solution proposée par le module imblearn.ensemble : des modèles d'ensembles destinés aux classes déséquilibrées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESUME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Model Name</th>        <th class=\"col_heading level0 col1\" >Mean Cross-Val Balanced Accuracy</th>        <th class=\"col_heading level0 col2\" >Mean Cross-Val Accuracy</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row0_col0\" class=\"data row0 col0\" >XGBoost</td>\n",
       "                        <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row0_col1\" class=\"data row0 col1\" >0.485788</td>\n",
       "                        <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row0_col2\" class=\"data row0 col2\" >0.670149</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row1_col0\" class=\"data row1 col0\" >CatBoost</td>\n",
       "                        <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row1_col1\" class=\"data row1 col1\" >0.484618</td>\n",
       "                        <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row1_col2\" class=\"data row1 col2\" >0.673348</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row2_col0\" class=\"data row2 col0\" >LightGBM</td>\n",
       "                        <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row2_col1\" class=\"data row2 col1\" >0.478885</td>\n",
       "                        <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row2_col2\" class=\"data row2 col2\" >0.668478</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row3_col0\" class=\"data row3 col0\" >Extra-Trees</td>\n",
       "                        <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row3_col1\" class=\"data row3 col1\" >0.475785</td>\n",
       "                        <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row3_col2\" class=\"data row3 col2\" >0.658890</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row4_col0\" class=\"data row4 col0\" >Random Forest</td>\n",
       "                        <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row4_col1\" class=\"data row4 col1\" >0.472810</td>\n",
       "                        <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row4_col2\" class=\"data row4 col2\" >0.665346</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row5_col0\" class=\"data row5 col0\" >Logistic Regression</td>\n",
       "                        <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row5_col1\" class=\"data row5 col1\" >0.456103</td>\n",
       "                        <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row5_col2\" class=\"data row5 col2\" >0.651881</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row6_col0\" class=\"data row6 col0\" >Gradient Boosting</td>\n",
       "                        <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row6_col1\" class=\"data row6 col1\" >0.448286</td>\n",
       "                        <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row6_col2\" class=\"data row6 col2\" >0.653104</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row7_col0\" class=\"data row7 col0\" >Perceptron</td>\n",
       "                        <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row7_col1\" class=\"data row7 col1\" >0.348820</td>\n",
       "                        <td id=\"T_d679c177_fb6a_11eb_93b4_c3edd8a299d5row7_col2\" class=\"data row7 col2\" >0.549656</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22f8d11ebe0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scordict = { \"Model Name\":[\"Random Forest\", 'Extra-Trees', 'Gradient Boosting', 'XGBoost', 'LightGBM', 'CatBoost','Logistic Regression', 'Perceptron'],\n",
    "            \"Mean Cross-Val Balanced Accuracy\": [rf1_bacc.mean(), etc1_bacc.mean(), gbc11_bacc.mean(), xgb1_bacc.mean(), lgbm1_bacc.mean(), cat1_bacc.mean(), logreg1_bacc.mean(), pclf_bacc.mean()],\n",
    "            \"Mean Cross-Val Accuracy\": [rf1_acc.mean(), etc1_acc.mean(), gbc11_acc.mean(), xgb1_acc.mean(), lgbm1_acc.mean(), cat1_acc.mean(), logreg1_acc.mean(), pclf_acc.mean()]\n",
    "           }\n",
    "df_scores = pd.DataFrame(scordict)\n",
    "df_scores.sort_values(by='Mean Cross-Val Balanced Accuracy', ascending=False).style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONCLUSION\n",
    "Le modèle \"XGBoost\" initialisé par défaut est le plus performant, mais reste insufisant avec un score inférieur à 50% (phénomène d'\"underfitting\").\n",
    "Nous allons tester dans un second temps les algorithmes spécifiquement destinées aux classifications déséquilibrées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished! See next file.\n"
     ]
    }
   ],
   "source": [
    "print('finished! See next file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
